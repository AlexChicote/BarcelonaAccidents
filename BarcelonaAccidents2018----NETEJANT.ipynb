{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import  math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utmToLatLng(zone, easting, northing, northernHemisphere=True):\n",
    "    \n",
    "    if not northernHemisphere:\n",
    "        northing = 10000000 - northing\n",
    "\n",
    "    a = 6378137\n",
    "    e = 0.081819191\n",
    "    e1sq = 0.006739497\n",
    "    k0 = 0.9996\n",
    "\n",
    "    arc = northing / k0\n",
    "    mu = arc / (a * (1 - math.pow(e, 2) / 4.0 - 3 * math.pow(e, 4) / 64.0 - 5 * math.pow(e, 6) / 256.0))\n",
    "\n",
    "    ei = (1 - math.pow((1 - e * e), (1 / 2.0))) / (1 + math.pow((1 - e * e), (1 / 2.0)))\n",
    "\n",
    "    ca = 3 * ei / 2 - 27 * math.pow(ei, 3) / 32.0\n",
    "\n",
    "    cb = 21 * math.pow(ei, 2) / 16 - 55 * math.pow(ei, 4) / 32\n",
    "    cc = 151 * math.pow(ei, 3) / 96\n",
    "    cd = 1097 * math.pow(ei, 4) / 512\n",
    "    phi1 = mu + ca * math.sin(2 * mu) + cb * math.sin(4 * mu) + cc * math.sin(6 * mu) + cd * math.sin(8 * mu)\n",
    "\n",
    "    n0 = a / math.pow((1 - math.pow((e * math.sin(phi1)), 2)), (1 / 2.0))\n",
    "\n",
    "    r0 = a * (1 - e * e) / math.pow((1 - math.pow((e * math.sin(phi1)), 2)), (3 / 2.0))\n",
    "    fact1 = n0 * math.tan(phi1) / r0\n",
    "\n",
    "    _a1 = 500000 - easting\n",
    "    dd0 = _a1 / (n0 * k0)\n",
    "    fact2 = dd0 * dd0 / 2\n",
    "\n",
    "    t0 = math.pow(math.tan(phi1), 2)\n",
    "    Q0 = e1sq * math.pow(math.cos(phi1), 2)\n",
    "    fact3 = (5 + 3 * t0 + 10 * Q0 - 4 * Q0 * Q0 - 9 * e1sq) * math.pow(dd0, 4) / 24\n",
    "\n",
    "    fact4 = (61 + 90 * t0 + 298 * Q0 + 45 * t0 * t0 - 252 * e1sq - 3 * Q0 * Q0) * math.pow(dd0, 6) / 720\n",
    "\n",
    "    lof1 = _a1 / (n0 * k0)\n",
    "    lof2 = (1 + 2 * t0 + Q0) * math.pow(dd0, 3) / 6.0\n",
    "    lof3 = (5 - 2 * Q0 + 28 * t0 - 3 * math.pow(Q0, 2) + 8 * e1sq + 24 * math.pow(t0, 2)) * math.pow(dd0, 5) / 120\n",
    "    _a2 = (lof1 - lof2 + lof3) / math.cos(phi1)\n",
    "    _a3 = _a2 * 180 / math.pi\n",
    "\n",
    "    latitude = 180 * (phi1 - fact1 * (fact2 + fact3 + fact4)) / math.pi\n",
    "\n",
    "    if not northernHemisphere:\n",
    "        latitude = -latitude\n",
    "\n",
    "    longitude = ((zone > 0) and (6 * zone - 183.0) or 3.0) - _a3\n",
    "\n",
    "    return latitude, longitude\n",
    "##correcting graphics of the letters. Having different accents and definitions is better if we get all names the same\n",
    "\n",
    "def posant_accents(it):\n",
    "    \n",
    "    if type(it) == str:\n",
    "        \n",
    "        ##lletra ç\n",
    "        \n",
    "        if '\\x87' in it:\n",
    "            nova = it.replace('\\x87','ç')\n",
    "        else:\n",
    "            nova = it\n",
    "\n",
    "        ###lletra i\n",
    "        if '¡' or 'Ã¯'or 'ï'or 'Ã\\xad'or 'í' in nova:\n",
    "            renova = nova.replace('¡', 'i').replace('Ã¯', 'i').replace('ï', 'i').\\\n",
    "            replace('Ã\\xad', 'i').replace('í', 'i')\n",
    "        else:\n",
    "            renova = nova\n",
    "        ###Lletra o\n",
    "        if '\\x95' or 'Ã³' or '¢' or 'ã³'or 'Ã²' or 'ò' in renova:\n",
    "            trinova = renova.replace('\\x95', 'o').replace('Ã³', 'o')\\\n",
    "            .replace('¢', 'o').replace('ã³', 'o').replace('Ã²', 'o').replace('ò', 'o')\n",
    "        else:\n",
    "            trinova = renova\n",
    "\n",
    "        if '¢' in trinova:\n",
    "\n",
    "            quatrinova = trinova.replace('¢', 'o')\n",
    "        else:\n",
    "            quatrinova = trinova\n",
    "\n",
    "        ###lletra e\n",
    "        if '\\x82' or 'Ã©' or 'é' or 'è'or 'Ãš' or '\\x8a' in quatrinova:\n",
    "            cinquinova = quatrinova.replace('\\x82', 'e').replace('Ã©', 'e').replace('é', 'e').replace('è', 'e').\\\n",
    "            replace('Ãš', 'e').replace('\\x8a', 'e')\n",
    "        else:\n",
    "            cinquinova = quatrinova\n",
    "\n",
    "        if '\\x85' or 'Ã\\xa0'in cinquinova:\n",
    "            sixinova = cinquinova.replace('\\x85', 'a').replace('Ã\\xa0', 'a').replace('à', 'a')\n",
    "        else:\n",
    "            sixinova = cinquinova\n",
    "\n",
    "        if 'Sarr' in sixinova:\n",
    "\n",
    "            septinova = 'Sarria'\n",
    "        else:\n",
    "            septinova = sixinova\n",
    "\n",
    "        if 'Ã§' in septinova:\n",
    "            vuitinova = septinova.replace('Ã§', 'ç')\n",
    "        else:\n",
    "            vuitinova = septinova\n",
    "\n",
    "        ##Lletra u\n",
    "        if 'ãº' or 'ú' or '£'in vuitinova:\n",
    "            nounova = vuitinova.replace('ãº', 'u').replace('ú', 'u').replace('£','u')\n",
    "        else:\n",
    "            nounova = vuitinova\n",
    "\n",
    "        if 'ã³' or 'ó' in nounova:\n",
    "\n",
    "            deunova = nounova.replace('ã³', 'o').replace('ó', 'o')\n",
    "        else:\n",
    "            deunova = nounova\n",
    "    else:\n",
    "        deunova = it\n",
    "    \n",
    "    return deunova\n",
    "\n",
    "####Causes a angles\n",
    "\n",
    "def cause_to_angles(it):\n",
    "    \n",
    "    if it == 'Alcoholemia':\n",
    "        it = 'DrunkDriving'\n",
    "    if it == 'Calçada en mal estat':\n",
    "        it = 'Road_damaged'\n",
    "    if it == 'Drogues o medicaments':\n",
    "        it = 'DUI'\n",
    "    if it == 'Estat de la senyalitzacio':\n",
    "        it = 'Signals_damaged'\n",
    "    if it == 'Exces de velocitat o inadequada':\n",
    "        it = 'Speeding'\n",
    "    if it == 'Factors meteorologics':\n",
    "        it = 'Weather'\n",
    "    if it == 'Objectes o animals a la calçada':\n",
    "        it = 'Objects or animals on the road'\n",
    "    if it == 'No hi ha causa mediata':\n",
    "        it = 'No mediate cause'\n",
    "\n",
    "        \n",
    "    return it\n",
    "\n",
    "##transalting to catalan\n",
    "\n",
    "def traduir_castella(word):\n",
    "    if type(word) == str:\n",
    "        if word.endswith('ismo'):\n",
    "            nova = word.replace('ismo', 'isme')\n",
    "        else:\n",
    "            nova = word\n",
    "        if 'ciclo' in nova:\n",
    "            renova = nova.replace('ciclo', 'cicle')\n",
    "        else:\n",
    "            renova = nova\n",
    "            \n",
    "        if renova.startswith('Cuadri'):\n",
    "            trinova = renova.replace('Cuadri', 'Quadri')\n",
    "        else:\n",
    "            trinova = renova\n",
    "        \n",
    "        if trinova.startswith('Camion'):\n",
    "            \n",
    "            quatrinova = trinova.replace('Camion', 'Camio rigid')\n",
    "        \n",
    "        else:\n",
    "            quatrinova = trinova\n",
    "            \n",
    "        if quatrinova.endswith('  camion'):\n",
    "            \n",
    "            cinquinova = quatrinova.replace('camion', 'camio')\n",
    "        else:\n",
    "            cinquinova = quatrinova\n",
    "            \n",
    "        if 'Tm'in cinquinova:\n",
    "            sixinova = cinquinova.replace('Tm', 'tones')\n",
    "        else:\n",
    "            sixinova = cinquinova\n",
    "        if '75cc' in sixinova:\n",
    "            septinova = sixinova.replace('75cc', ' 75 cc')\n",
    "        else:\n",
    "            septinova = sixinova\n",
    "        if '> 75' in septinova:\n",
    "            octinova = septinova.replace('> 75', '>= 75')\n",
    "        else:\n",
    "            octinova = septinova\n",
    "        if octinova == 'Tranvia o tren':\n",
    "            noninova = 'Tren o tramvia'\n",
    "        else:\n",
    "            noninova = octinova\n",
    "        if 'de obras' in noninova:\n",
    "            nova2 = noninova.replace('de obras', \"d'obres i serveis\")\n",
    "        else:\n",
    "            nova2 = noninova\n",
    "        \n",
    "        if 'Otros' or 'terreno' or 'articulado' or 'vehic. a' or 'Todo' or '17 plazas' in nova2:\n",
    "            \n",
    "            nova3 = nova2.replace('Otros', 'Altres').replace('terreno', 'terreny').\\\n",
    "            replace('articulado', 'articulat').replace('vehic. a', 'vehicles amb').replace('Todo', 'Tot')\\\n",
    "            .replace('17 plazas',' 17')\n",
    "        else:\n",
    "            nova3 = nova2\n",
    "        if nova3 == 'Tractocamion':\n",
    "            nova4 = \"Tractor camio\"\n",
    "        else:\n",
    "            nova4 = nova3\n",
    "    else:\n",
    "        nova4 = word\n",
    "    \n",
    "    return nova4\n",
    "\n",
    "def ped_to_angles(it):\n",
    "    if it == 'Desconegut':\n",
    "        it = 'unknown'\n",
    "    if it == 'Creuar per fora pas de vianants':\n",
    "        it = 'Crossing outside ped crossing'\n",
    "    if it == 'Desobeir el senyal del semafor':\n",
    "        it = 'Disobey the traffic light signal'\n",
    "    if it == 'Transitar a peu per la calçada':\n",
    "        it = 'Cross through the road'\n",
    "    if it == 'Altres':\n",
    "        it = 'Other'\n",
    "    if it == 'Desobeir altres senyals':\n",
    "        it = 'Disobey other signals'\n",
    "    if it == 'No es causa del  vianant':\n",
    "        it = 'No peds fault'\n",
    "\n",
    "        \n",
    "    return it\n",
    "\n",
    "\n",
    "def setmana_a_angles(it):\n",
    "    if it == 'Dilluns':\n",
    "        it = 'Monday'\n",
    "    if it == 'Dimarts':\n",
    "        it = 'Tuesday'\n",
    "    if it == 'Dimecres':\n",
    "        it = 'Wednesday'\n",
    "    if it == 'Dijous':\n",
    "        it = 'Thursday'\n",
    "    if it == 'Divendres':\n",
    "        it = 'Friday'\n",
    "    if it == 'Dissabte':\n",
    "        it = 'Saturday'\n",
    "    if it == 'Diumenge':\n",
    "        it = 'Sunday'\n",
    "        \n",
    "    return it\n",
    "\n",
    "\n",
    "def mes_a_angles(it):\n",
    "    if it == 'Gener':\n",
    "        it = 'January'\n",
    "    if it == 'Febrer':\n",
    "        it = 'February'\n",
    "    if it == 'Març':\n",
    "        it = 'March'\n",
    "    if it == 'Abril':\n",
    "        it = 'April'\n",
    "    if it == 'Maig':\n",
    "        it = 'May'\n",
    "    if it == 'Juny':\n",
    "        it = 'June'\n",
    "    if it == 'Juliol':\n",
    "        it = 'July'\n",
    "    if it == 'Agost':\n",
    "        it = 'August'\n",
    "    if it == 'Setembre':\n",
    "        it = 'September'\n",
    "    if it == 'Octubre':\n",
    "        it = 'October'\n",
    "    if it == 'Novembre':\n",
    "        it = 'November'\n",
    "    if it == 'Desembre':\n",
    "        it = 'December'\n",
    "        \n",
    "    return it\n",
    "\n",
    "def counting_non_zeros(tup):\n",
    "    count = 0\n",
    "    for i in tup:\n",
    "        if i > 0:\n",
    "            count+=1\n",
    "    if count == 0:\n",
    "        count = 1\n",
    "    return count\n",
    "\n",
    "def debugging_strings(row, word):\n",
    "    word = str(word)\n",
    "    count = 0\n",
    "    for i in row:\n",
    "        if word in i:\n",
    "            count =1\n",
    "    return count\n",
    "\n",
    "def mercedes(word):\n",
    "    \"\"\"Corregir tots els mercedes\"\"\"\n",
    "    if word in ['mercedes-benz', 'mercedesb', 'mecedes']:\n",
    "        word = 'mercedes'\n",
    "    return word\n",
    "\n",
    "\n",
    "def licenses(license):\n",
    "    \n",
    "    if 'A' in license:\n",
    "        license = 'motorbike_license'\n",
    "    elif 'BTP' in license:\n",
    "        license = 'taxis_ambulances_license'\n",
    "    elif 'B' in license:\n",
    "        \n",
    "        license = 'regular_license'\n",
    "    elif 'D' in license:\n",
    "        license = 'bus_license'\n",
    "    elif 'C' in license:\n",
    "        license = 'van_license'\n",
    "\n",
    "    return license        \n",
    "\n",
    "def fixing_codes(i):\n",
    "   \n",
    "    if i in desconegut_llista:\n",
    "        i = int(-1)\n",
    "    elif type(i) == float:\n",
    "        i = int(i)\n",
    "        \n",
    "    elif (type(i) == str) and len(i) > 4:\n",
    "        i = int(''.join(i.split(\"-\", 2)[2:]))\n",
    "    elif (type(i) == str) and len(i) <= 4:\n",
    "        i = int(''.join(i.split('.')[0]))\n",
    "\n",
    "    else:\n",
    "        i = int(i)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accidents Done\n",
      "Causes Done\n",
      "People Done\n",
      "Types Done\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "###ACCIDENTS\n",
    "accidents = {}\n",
    "\n",
    "anys = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n",
    "\n",
    "for an in anys:\n",
    "    if int(an) < 2015:\n",
    "        encoding = 'ISO-8859-15'\n",
    "    else:\n",
    "        encoding = 'utf-8'\n",
    "    \n",
    "    file = '/Users/fcbnyc/dsi/databases/BarcelonaAccidents/{}-files/{}_accidents_accidents_gu_bcn_{}.csv'.format(an, an, an)\n",
    "    accidents[an] = pd.read_csv(file, encoding=encoding)\n",
    "for key in accidents.keys():\n",
    "    if len(accidents[key].columns) == 25:\n",
    "        accidents[key].columns = ['incident_#', 'district_code', 'district', 'neighborhood_code', 'neighborhood',\\\n",
    "                                   'street_code', 'street', 'zip_code', 'weekday_name', 'weekday','type_of_day', 'year',\\\n",
    "                                    'month','month_name', 'day_month','hour_day', 'shift','pedestrian_cause','#_deaths',\\\n",
    "                                   'minor_injuries', 'severe_injuries','amount_victims','amount_vehicles_involved','point_y', 'point_x']\n",
    "        \n",
    "    else:\n",
    "        accidents[key].columns = ['incident_#', 'district_code', 'district', 'neighborhood_code', 'neighborhood',\\\n",
    "                                   'street_code', 'street', 'zip_code', 'weekday_name', 'weekday','type_of_day', 'year',\\\n",
    "                                    'month','month_name', 'day_month','hour_day', 'shift','pedestrian_cause','#_deaths',\\\n",
    "                                    'minor_injuries', 'severe_injuries','amount_victims','amount_vehicles_involved','point_x', 'point_y',\\\n",
    "                                   'long', 'lat']\n",
    "    accidents[key]['point_x'] = [float(x.replace(',', '.')) if type(x) == str else x for x in accidents[key]['point_x']]\n",
    "    accidents[key]['point_y'] = [float(x.replace(',', '.')) if type(x) == str else x for x in accidents[key]['point_y']]\n",
    "    accidents[key]['longitude'] = [b for a,b in accidents[key][['point_x', 'point_y']].apply(lambda row: utmToLatLng(31, row['point_x'], row['point_y']), axis=1)]\n",
    "    accidents[key]['latitude'] = [a for a,b in accidents[key][['point_x', 'point_y']].apply(lambda row: utmToLatLng(31, row['point_x'], row['point_y']), axis=1)]\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame()\n",
    "prova = 0\n",
    "\n",
    "for key in accidents.keys():\n",
    "    prova = prova + len(accidents[key])\n",
    "    \n",
    "    dataframe = pd.concat([dataframe, accidents[key]])\n",
    "\n",
    "\n",
    "\n",
    "dataframe = dataframe[dataframe['#_deaths'].notnull()]\n",
    "dataframe.reset_index(inplace=True)\n",
    "##Erasing type of day because all days are laboral\n",
    "dataframe.drop(['month', 'weekday', 'type_of_day', 'point_x', 'point_y', 'lat', 'long'], axis=1, inplace=True)\n",
    "dataframe = dataframe[~dataframe['incident_#'].duplicated(keep='last')]\n",
    "dataframe['neighborhood'] = dataframe['neighborhood'].apply(lambda x: posant_accents(x)).replace('el Poble-sec', 'el Poble Sec')\n",
    "desconegut_llista = dataframe[dataframe['neighborhood'] == 'Desconegut']['neighborhood_code'].unique()\n",
    "dataframe['neighborhood_code'] = dataframe['neighborhood_code'].apply(lambda x: fixing_codes(x))\n",
    "dataframe['pedestrian_cause'] = dataframe['pedestrian_cause'].apply(lambda x: posant_accents(x)).apply(lambda x: ped_to_angles(x))\n",
    "dataframe['street'] = dataframe['street'].apply(lambda x: posant_accents(x))\n",
    "dataframe['shift'] = ['morning' if x == 'Matí' else 'afternoon/evening' if x == 'Tarda' else 'night' if x == 'Nit' else 'watchout' for x in dataframe['shift']]\n",
    "dataframe['month_name'] = dataframe['month_name'].apply(lambda x: mes_a_angles(x))\n",
    "dataframe['weekday_name'] = dataframe['weekday_name'].apply(lambda x: setmana_a_angles(x))\n",
    "dataframe['incident_#'] = dataframe['incident_#'].str.strip()\n",
    "dataframe.to_csv('accidents_amb_2018.csv')\n",
    "accidents = dataframe.copy()\n",
    "\n",
    "print(\"Accidents Done\")\n",
    "\n",
    "###CAUSES\n",
    "\n",
    "causes = {}\n",
    "\n",
    "anys = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n",
    "\n",
    "for an in anys:\n",
    "    if int(an) < 2015:\n",
    "        encoding = 'ISO-8859-15'\n",
    "    else:\n",
    "        encoding = 'utf-8'\n",
    "    \n",
    "    file = '/Users/fcbnyc/dsi/databases/BarcelonaAccidents/{}-files/{}_accidents_causes_gu_bcn_{}.csv'.format(an, an, an)\n",
    "    if int(an) == 2017:\n",
    "        causes[an] = pd.read_csv(file, usecols=[0,18],encoding=encoding)\n",
    "    else:\n",
    "        causes[an] = pd.read_csv(file, usecols=[0,17],encoding=encoding)\n",
    "\n",
    "dataframe = pd.DataFrame()\n",
    "prova = 0\n",
    "\n",
    "for key in causes.keys():\n",
    "    prova = prova + len(causes[key])\n",
    "    causes[key].columns = ['incident_#', 'cause']\n",
    "    \n",
    "    dataframe = pd.concat([dataframe, causes[key]])\n",
    "\n",
    "dataframe['cause'] = dataframe['cause'].apply(lambda x: posant_accents(x)).apply(lambda x: cause_to_angles(x))\n",
    "dataframe['cause'].fillna('non_existing', inplace=True)\n",
    "dataframe = dataframe.groupby('incident_#').cause.agg(['count', ('cause', ','.join)]).reset_index()\n",
    "dataframe.rename(columns={'count':'cause_count'}, inplace=True)\n",
    "dataframe['incident_#'] = dataframe['incident_#'].str.strip()\n",
    "\n",
    "cause_1 = []\n",
    "\n",
    "max_count = max(dataframe['cause_count'])\n",
    "for a,b in zip(dataframe['cause_count'], dataframe['cause']):\n",
    "    stripped_list = b.split(',')\n",
    "    added_list = ['non_existing'] * (max_count- a)\n",
    "    stripped_list.extend(added_list)\n",
    "    cause_1.append(stripped_list)\n",
    "dataframe = pd.concat([dataframe, pd.DataFrame(cause_1, columns=['cause_1', 'cause_2', 'cause_3'])], axis=1)\n",
    "dataframe.drop('cause', axis=1, inplace=True)\n",
    "dataframe.to_csv('causes_amb_2018.csv')\n",
    "causes = dataframe.copy()\n",
    "total = pd.merge(accidents,causes, on='incident_#', how='left')\n",
    "total['cause_count'].fillna(0,inplace=True)\n",
    "for col in ['cause_1', 'cause_2', 'cause_3']:\n",
    "    total[col].fillna('unknown', inplace=True)\n",
    "causes_col_index = [total.columns.get_loc(x) for x in total.columns if x.startswith('cause') and not(x.endswith('count'))]\n",
    "cause_col_names  = [x for x in total.columns if x.startswith('cause') and not(x.endswith('count'))]\n",
    "causes_unique = []\n",
    "for col in cause_col_names:\n",
    "    for i in total[col].unique():\n",
    "        causes_unique.append(i)\n",
    "        \n",
    "causes_unique = set(causes_unique)\n",
    "for x in causes_unique:\n",
    "    #column_name = '_is' + x\n",
    "    total['is_cause_' + x] = [1 if x in row[causes_col_index[0]+1:causes_col_index[-1]+2]else 0 for row in total.itertuples()]\n",
    "\n",
    "print(\"Causes Done\")\n",
    "##PeOPLe\n",
    "people = {}\n",
    "\n",
    "for an in anys:\n",
    "    file = '/Users/fcbnyc/dsi/databases/BarcelonaAccidents/{}-files/{}_accidents_persones_gu_bcn_{}.csv'.format(an, an, an)\n",
    "    if int(an) < 2014:\n",
    "        encoding = 'ISO-8859-15'\n",
    "        pont = pd.read_csv(file,encoding=encoding)\n",
    "        columnes = []\n",
    "        columnes.append(pont.columns[0])\n",
    "        columnes.extend(pont.columns[18:22])\n",
    "        people[an] = pont[columnes]\n",
    "        \n",
    "    elif int(an) == 2014:\n",
    "        encoding = 'ISO-8859-15'\n",
    "        pont = pd.read_csv(file,encoding = encoding)\n",
    "        columnes = []\n",
    "        columnes.append(pont.columns[0])\n",
    "        columnes.extend(pont.columns[17:21])\n",
    "        people[an] = pont[columnes]\n",
    "        \n",
    "    elif an == '2015':\n",
    "        encoding = 'ISO-8859-15'\n",
    "        pont = pd.read_csv(file,encoding = encoding)\n",
    "        columnes = []\n",
    "        columnes.append(pont.columns[0])\n",
    "        columnes.extend(pont.columns[17:21])\n",
    "        people[an] = pont[columnes]\n",
    "        \n",
    "    else:\n",
    "        encoding = 'utf-8'\n",
    "        pont = pd.read_csv(file, encoding = encoding)\n",
    "        columnes = []\n",
    "        columnes.append(pont.columns[0])\n",
    "        columnes.extend(pont.columns[18:22])\n",
    "        people[an] = pont[columnes]\n",
    "    \n",
    "    \n",
    "dataframe = pd.DataFrame()\n",
    "prova = 0\n",
    "\n",
    "for key in people.keys():\n",
    "    prova = prova + len(people[key])\n",
    "    if int(key) < 2016:\n",
    "        \n",
    "        people[key].columns = ['incident_#', 'vehicle', 'gender', 'role_people', 'age']\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        people[key].columns = ['incident_#', 'vehicle', 'gender', 'age', 'role_people']\n",
    "    dataframe = pd.concat([dataframe, people[key]])\n",
    "\n",
    "dataframe['gender'] = ['male' if x =='Home' else 'female' if x == 'Dona' else 'unknown' for x in dataframe['gender']]\n",
    "dataframe['role_people'] = ['driver' if x =='Conductor' else 'passenger' if x == 'Passatger' else 'pedestrian' for x in dataframe['role_people']]\n",
    "dataframe['vehicle'] = dataframe['vehicle'].apply(lambda x: posant_accents(x)).apply(lambda x: traduir_castella(x))\n",
    "dataframe['vehicle'] = ['Motorbike' if x == 'Motocicleta' else\\\n",
    " 'Car' if x in ['Turisme', 'Autocaravana', 'Tot terreny'] else \\\n",
    " 'Moped' if x == \"Ciclomotor\" else \\\n",
    " 'Bicycle' if x == 'Bicicleta' else\\\n",
    " 'Bus' if x in ['Autobus', 'Autobus articulat', 'Autocar', 'Microbus <= 17'] else\\\n",
    " 'Van' if x == 'Furgoneta' else\\\n",
    " 'Truck' if x in ['Camio rigid <= 3,5 tones', 'Camio rigid > 3,5 tones', 'Tractor camio'] else 'Other vehicles' for x in dataframe['vehicle']]\n",
    "\n",
    "dataframe = dataframe.groupby('incident_#').agg(['count',('second', ','.join)]).reset_index()\n",
    "dataframe.columns = ['incident_#','people_count', 'age', 'a', 'gender', 'b', 'role_people',\n",
    "                'c', 'vehicle']\n",
    "dataframe.drop(['a', 'b', 'c'], axis=1,inplace=True)\n",
    "dataframe['incident_#'] = dataframe['incident_#'].str.strip()\n",
    "for col in dataframe.columns[2:]:   \n",
    "    people_1 = []\n",
    "\n",
    "    max_count = max(dataframe['people_count'])\n",
    "    for a,b in zip(dataframe['people_count'], dataframe[col]):\n",
    "        stripped_list = str(b).split(',')\n",
    "        stripped_list.extend(['non_existing'] * (max_count- a))\n",
    "        people_1.append(stripped_list)\n",
    "    #print(col)\n",
    "    dataframe = pd.concat([dataframe, pd.DataFrame(people_1, columns=[col +'_' +str(x) for x in range(1,max_count + 1)])], axis=1)\n",
    "    dataframe.drop(col,axis=1,inplace=True)\n",
    "\n",
    "dataframe.to_csv('people_amb_2018.csv')\n",
    "        \n",
    "people = dataframe.copy()\n",
    "\n",
    "total = pd.merge(total,people, on='incident_#', how='left')\n",
    "for col in [x for x in total.columns if x.startswith('people') and not(x.endswith('count'))]:\n",
    "    total[col].fillna('non_existing', inplace=True)\n",
    "for col in [x for x in total.columns if (x.startswith('role')) or (x.startswith('gender')) or (x.startswith('vehicle_'))]:\n",
    "    total[col].fillna('non_existing', inplace=True)\n",
    "    total[col] = [str(x).replace('0', 'non_existing') for x in total[col]]\n",
    "    total[col] = [str(x).replace('0','non_existing').replace('0','Desconegut') for x in total[col]]\n",
    "for col in total.columns:\n",
    "    total[col].fillna('0',inplace=True)\n",
    "    \n",
    "vehicle_col_names = [x for x in total.columns if x.startswith('vehicle_')]\n",
    "llista_vehicles = []\n",
    "for col in vehicle_col_names:\n",
    "    for i in total[col].unique():\n",
    "        if i not in llista_vehicles:\n",
    "            llista_vehicles.append(i)\n",
    "total['is_vehicle_unknown'] =[1 if x in ['non_existing', 'unknown'] else 0 for x in total['vehicle_1']]\n",
    "llista_vehicles.remove('non_existing')\n",
    "\n",
    "for i in llista_vehicles:\n",
    "    total['is_vehicle_' + i] = [debugging_strings(row[1:],i) for row in total[vehicle_col_names].itertuples()]\n",
    "\n",
    "roles_col_names = [x for x in total.columns if 'role' in x]\n",
    "for role in total['role_people_1'].unique():\n",
    "    total['is_role_' + role] = [debugging_strings(row[1:], role) for row in total[roles_col_names].itertuples()]\n",
    "        \n",
    "age_col_names = [x for x in total.columns if x.startswith('age_')]\n",
    "age_col_index = [total.columns.get_loc(x) for x in total.columns if x.startswith('age_')]\n",
    "\n",
    "for col in age_col_names:\n",
    "    total[col] = [str(x).replace('non_existing', '0').replace('Desconegut', '0') for x in total[col]]\n",
    "    total[col] = total[col].astype(int)\n",
    "\n",
    "total['age_avg'] = [sum(row[age_col_index[0] +1:age_col_index[-1] + 2])/counting_non_zeros(row[age_col_index[0] +1:age_col_index[-1] + 2])\\\n",
    "                    for row in total.itertuples()]\n",
    "age_role_col_names = [x for x in total.columns if ('age_' in x )or ('role_' in x)]\n",
    "gender_role_col_index = [total.columns.get_loc(x) for x in total.columns if ('age_' in x )or ('role_' in x)]\n",
    "age_driver = []\n",
    "is_young_driver = []\n",
    "for row in total[age_role_col_names].itertuples():\n",
    "    age = 0\n",
    "    count = 0\n",
    "    young = 0\n",
    "    for x in range(0,len(row)):\n",
    "        if row[x] == 'driver':\n",
    "            count=count + 1\n",
    "            age = age + row[x-21]\n",
    "            if row[x-21] <25:\n",
    "                young = young + 1\n",
    "    if count == 0:\n",
    "        age_driver.append(count)\n",
    "    else:\n",
    "        age_driver.append(age/count)\n",
    "    if young >0:\n",
    "        is_young_driver.append(young)\n",
    "    else:\n",
    "        is_young_driver.append(young) \n",
    "\n",
    "total['age_driver'] = age_driver\n",
    "total['is_young_driver'] = is_young_driver\n",
    "\n",
    "gender_role_col_names = [x for x in total.columns if ('gender_' in x )or ('role_' in x)]\n",
    " \n",
    "gender_role_col_index = [total.columns.get_loc(x) for x in total.columns if ('age_' in x )or ('role_' in x)]\n",
    "is_female_driver = []\n",
    "is_male_driver = []\n",
    "for row in total[gender_role_col_names].itertuples():\n",
    "    is_male = 0\n",
    "    is_female = 0\n",
    "    count = 0\n",
    "    for x in range(0,len(row)):\n",
    "        if row[x] == 'driver':\n",
    "            if row[x-21] == 'male':\n",
    "                is_male +=1\n",
    "            if row[x-21] == 'female':\n",
    "                is_female +=1\n",
    "            \n",
    "\n",
    "    is_male_driver.append(is_male)\n",
    "    is_female_driver.append(is_female)\n",
    "\n",
    "            \n",
    "total['is_male_driver'] = is_male_driver\n",
    "total['is_female_driver'] = is_female_driver\n",
    "\n",
    "print(\"People Done\")\n",
    "\n",
    "##TYPES\n",
    "\n",
    "types = {}\n",
    "\n",
    "anys = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n",
    "\n",
    "for an in anys:\n",
    "    if int(an) < 2016:\n",
    "        encoding = 'ISO-8859-15'\n",
    "    else:\n",
    "        encoding = 'utf-8'\n",
    "    \n",
    "    file = '/Users/fcbnyc/dsi/databases/BarcelonaAccidents/{}-files/{}_accidents_tipus_gu_bcn_{}.csv'.format(an, an, an)\n",
    "        \n",
    "    types[an] = pd.read_csv(file, usecols=[0,17],encoding=encoding)\n",
    "    \n",
    "\n",
    "dataframe = pd.DataFrame()\n",
    "prova = 0\n",
    "\n",
    "for key in types.keys():\n",
    "    prova = prova + len(types[key])\n",
    "    types[key].columns = ['incident_#', 'accident_type']\n",
    "    \n",
    "    dataframe = pd.concat([dataframe, types[key]])\n",
    "    \n",
    "dataframe['accident_type'] = dataframe['accident_type'].apply(lambda x: posant_accents(x)).map({'Atropellament': 'run_over',\n",
    "                                                              'Col.lisio lateral': 'lateral_collision',\n",
    "                                                              'Xoc contra element estatic': 'crash_into_stationary',\n",
    "                                                              'Abast': 'rear-end_collision',\n",
    "                                                               'Col.lisio frontal':'frontal_collision',\n",
    "                                                              'Col.lisio fronto-lateral':'frontal-lateral_collision',\n",
    "                                                              'Caiguda (dues rodes)':'fall--motorcycle',\n",
    "                                                              'Abast multiple':'multiple_rear-end_collision',\n",
    "                                                              'Caiguda interior vehicle':'fall_inside_vehicle',\n",
    "                                                              'Altres':'Other_types',\n",
    "                                                              'Bolcada (mes de dues rodes)':'overturning',\n",
    "                                                              'Desconegut':'unknown',\n",
    "                                                              'Sortida de via amb xoc o col.lisio':'run-off_with_crash_or_collision',\n",
    "                                                              'Encalç':'rear-end_collision',\n",
    "                                                              'Sortida de via amb bolcada':'run-off_with_overturning',\n",
    "                                                              'Xoc amb animal a la calçada':'crash_into_animal_on_road',\n",
    "                                                              'Resta sortides de via':'run-off_not_included_previously'})\n",
    "\n",
    "dataframe = dataframe.groupby('incident_#').agg(['count',('type_count', ','.join)]).reset_index()\n",
    "\n",
    "dataframe.columns = ['incident_#', 'type_count', 'accident_type']\n",
    "dataframe['incident_#'] = dataframe['incident_#'].str.strip()\n",
    "\n",
    "for col in dataframe.columns[2:]:   \n",
    "    people_1 = []\n",
    "\n",
    "    max_count = max(dataframe['type_count'])\n",
    "    for a,b in zip(dataframe['type_count'], dataframe[col]):\n",
    "        stripped_list = str(b).split(',')\n",
    "        stripped_list.extend([0] * (max_count- a))\n",
    "        people_1.append(stripped_list)\n",
    "    #print(col)\n",
    "    dataframe = pd.concat([dataframe, pd.DataFrame(people_1, columns=[col + '_'+ str(x) for x in range(1,max_count + 1)])], axis=1)\n",
    "    dataframe.drop(col,axis=1,inplace=True)\n",
    "\n",
    "dataframe.to_csv('types_amb_2018.csv')\n",
    "types = dataframe.copy()\n",
    "total = pd.merge(total,types, on='incident_#', how='left')\n",
    "type_col_index = [total.columns.get_loc(x) for x in total.columns if 'type' in x]\n",
    "type_col_names  = [x for x in total.columns if 'type' in x]\n",
    "total['type_count'].fillna(0,inplace=True)\n",
    "total['accident_type_1'].fillna('unknown',inplace=True)\n",
    "total['accident_type_1'] = [str(x).replace('0', 'unknown') for x in total['accident_type_1']]\n",
    "for col in type_col_names[2:]:\n",
    "    total[col] = [str(x).replace('0', 'non_existing').replace('nan', 'non_existing') for x in total[col]]\n",
    "    total[col].fillna('non_existing',inplace=True)\n",
    "                                \n",
    "                            \n",
    "total.fillna('non_existing',inplace=True)\n",
    "\n",
    "for i in total['accident_type_1'].value_counts().index:\n",
    "    if total['accident_type_1'].value_counts()[i] > 200:\n",
    "        total['is_type_' + i] = [debugging_strings(row[2:5],i) for row in total[type_col_names].itertuples()]\n",
    "\n",
    "print(\"Types Done\")\n",
    "\n",
    "###VEHICLES\n",
    "\n",
    "vehicles = {}\n",
    "\n",
    "anys = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n",
    "\n",
    "for an in anys:\n",
    "    if int(an) < 2016:\n",
    "        encoding = 'ISO-8859-15'\n",
    "    else:\n",
    "        encoding = 'utf-8'\n",
    "    \n",
    "    file = '/Users/fcbnyc/dsi/databases/BarcelonaAccidents/{}-files/{}_accidents_vehicles_gu_bcn_{}.csv'.format(an, an, an)\n",
    "        \n",
    "    if an != '2018':\n",
    "        pont = pd.read_csv(file, encoding=encoding)\n",
    "        columnes = []\n",
    "        columnes.append(pont.columns[0])\n",
    "        columnes.extend(pont.columns[18:23])\n",
    "        vehicles[an] = pont[columnes]\n",
    "    else:\n",
    "        pont = pd.read_csv(file, encoding=encoding)\n",
    "        columnes = []\n",
    "        columnes.append(pont.columns[0])\n",
    "        columnes.extend(pont.columns[19:24])\n",
    "        vehicles[an] = pont[columnes]\n",
    "    \n",
    "\n",
    "dataframe = pd.DataFrame()\n",
    "prova = 0\n",
    "\n",
    "for key in vehicles.keys():\n",
    "    prova = prova + len(vehicles[key])\n",
    "    vehicles[key].columns = ['incident_#', 'vehicle_model', 'vehicle_brand', \"vehicle_color\", 'license_class', 'senority_license']\n",
    "    \n",
    "    dataframe = pd.concat([dataframe, vehicles[key]])\n",
    "dataframe['vehicle_color'] = dataframe['vehicle_color'].apply(lambda x: posant_accents(x)).map({'Negre': 'black',\n",
    "                                                              'Blanc': 'white', 'Altres':'others', 'Gris': 'gray',\n",
    "                                                              'Vermell': 'red', 'Blau':'blue','Verd': 'green',\n",
    "                                                              'Platejat': 'silver','Groc': 'yellow','Beige':'beige',\n",
    "                                                              'Marro':'brown','Taronja':'orange','Daurat':'gold',\n",
    "                                                              'Violeta':'purple','Rosa':'pink', 'Negre/Groc':'black/yellow',\n",
    "                                                              'granate':'maroon'})\n",
    "dataframe['vehicle_color'].fillna('unknown',inplace=True)\n",
    "dataframe['vehicle_model'].fillna('unknown',inplace=True)\n",
    "dataframe = dataframe[dataframe['incident_#'].notnull()]\n",
    "dataframe['senority_license'] = dataframe['senority_license'].replace('Desconegut', '0')\n",
    "dataframe['license_class'].replace(['Desconegut', 'Es desconeix'], 'unknown',inplace=True)\n",
    "dataframe['vehicle_model'].replace('Desconegut', 'unknown',inplace=True)\n",
    "dataframe['vehicle_brand'].replace('Desconegut', 'unknown',inplace=True)\n",
    "dataframe = dataframe.groupby('incident_#').agg(['count',('vehicle_count', ','.join)]).reset_index()\n",
    "dataframe.columns = ['incident_#', 'vehicle_count', 'vehicle_model', 'a',\n",
    "                    'vehicle_brand', 'b', 'vehicle_color', 'c', 'license_class', 'd', 'senority_license']\n",
    "dataframe.drop(['a','b','c', 'd'], axis=1, inplace=True)\n",
    "dataframe['incident_#'] = dataframe['incident_#'].str.strip()\n",
    "dataframe['vehicle_model'] = [s.replace(',', '') for s in dataframe['vehicle_model']]\n",
    "for col in dataframe.columns[2:]:   \n",
    "    people_1 = []\n",
    "\n",
    "    max_count = max(dataframe['vehicle_count'])\n",
    "    for a,b in zip(dataframe['vehicle_count'], dataframe[col]):\n",
    "        stripped_list = str(b).split(',')\n",
    "        stripped_list.extend([0] * (max_count- a))\n",
    "        people_1.append(stripped_list)\n",
    "        #print(len(stripped_list))\n",
    "    #print(col)\n",
    "    dataframe = pd.concat([dataframe, pd.DataFrame(people_1, columns=[col +'_' +str(x) for x in range(1,max_count + 1)])], axis=1)\n",
    "    dataframe.drop(col,axis=1,inplace=True)\n",
    "    \n",
    "dataframe.to_csv('vehicles_amb_2018.csv')\n",
    "\n",
    "vehicles = dataframe.copy()\n",
    "total = pd.merge(total,vehicles, on='incident_#', how='left')\n",
    "for col in [x for x in total.columns if (x.startswith('vehicle_brand')) or (x.startswith('vehicle_color'))]:\n",
    "    total[col] = total[col].str.replace('0', 'non_existing')\n",
    "    total[col] = [str(x).lower().strip().replace('.','').replace(' ', '') for x in total[col]]\n",
    "    total[col].fillna('non_existing',inplace=True)\n",
    "for col in total.columns:\n",
    "    total[col].fillna(0,inplace=True)\n",
    "##not using model because has too many unique values\n",
    "vehicle_brand_col_names = [x for x in total.columns if x.startswith('vehicle_brand_')]\n",
    "for col in vehicle_brand_col_names:\n",
    "    total[col] = total[col].apply(lambda x: mercedes(x))\n",
    "    total[col] = total[col].str.replace('nan', 'non_existing')\n",
    "for x in total['vehicle_brand_1'].value_counts()[0:20].index:\n",
    "    total['is_vehicle_brand_' + x] = [debugging_strings(row[1:],x) for row in total[vehicle_brand_col_names].itertuples()]\n",
    "vehicle_color_col_names = [x for x in total.columns if x.startswith('vehicle_color_')]\n",
    "for col in vehicle_color_col_names:\n",
    "    total[col] = total[col].str.replace('nan','unknown')\n",
    "for x in total['vehicle_color_1'].value_counts().index:\n",
    "    total['is_vehicle_color_' + x] = [debugging_strings(row[1:],x) for row in total[vehicle_color_col_names].itertuples()]\n",
    "\n",
    "vehicle_license_col_names = [x for x in total.columns if x.startswith('license_class')]\n",
    "for col in vehicle_license_col_names:\n",
    "    total[col] = total[col].apply(lambda x: posant_accents(x))\n",
    "    total[col] =total[col].str.replace('0', 'non-existing').replace('Sense permis','no_license').\\\n",
    "    replace('Llicencia', 'moped_permit').replace('AM', 'moped_permit')\n",
    "    total[col].fillna('non-existing',inplace=True)\n",
    "    total[col] = total[col].apply(lambda x: licenses(x))\n",
    "    \n",
    "for i in total['license_class_1'].unique():\n",
    "    total['is_license_class_' + i] = [debugging_strings(row[1:],i) for row in total[vehicle_license_col_names].itertuples()]\n",
    "\n",
    "senority_col_names = [x for x in total.columns if x.startswith('senority_')]\n",
    "for col in senority_col_names:\n",
    "    total[col] = [str(x).replace('non_existing', '0').replace('Desconegut', '0') for x in total[col]]\n",
    "    total[col] = total[col].astype(int)\n",
    "\n",
    "total['senority_avg'] = [sum(row[1:])/counting_non_zeros(row[1:])\\\n",
    "                    for row in total[senority_col_names].itertuples()]\n",
    "total.to_csv('total_accidents_2018.csv', encoding='utf-8')    \n",
    "\n",
    "print('DONE')\n",
    "\n",
    "# print(total.isnull().sum().sum())\n",
    "# total.to_csv('total_accidents_2018.csv', encoding='utf-8')\n",
    "##Stripping all values\n",
    "# total_obj = total.select_dtypes(['object'])\n",
    "# total[total_obj.columns] = total_obj.apply(lambda x: x.str.strip())\n",
    "##Next step is to create a column for cause, people, types and vehicles\n",
    "##creating columns for:\n",
    "# Number of each gender\n",
    "#mean age of driversDONE\n",
    "#gender of driversDONE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv('total_accidents_2018.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fcbnyc/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = pd.read_csv('total_accidents_2018.csv', encoding='utf-8')\n",
    "aa.isnull().sum().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
